# 2026-02-13 Daily Papers (Top 5)

## 1. [The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies](https://huggingface.co/papers/2602.09877)
**Upvotes**: 177 | **도입 난이도**: 상 | **신뢰도**: 중

**태그**: Agent, Safety, Self-Evolution

![Thumbnail](images/The_Devil_Behind_Moltbook_Anthropic_Safety_is_Always_Vanishing_in_Self-Evolving_AI_Societies_img.jpg)

### 📌 한 줄 요약
자체 진화하는 AI 에이전트 시스템은 안전성 저하가 필연적이므로, 외부 감독이나 새로운 안전 유지 메커니즘이 필요하다.

### 🔑 핵심 포인트
- 자체 진화, 격리, 안전성 불변의 '자체 진화 딜레마'를 제시
- 정보 이론 기반으로 안전성을 인간 가치 분포와의 발산으로 정의
- 실험을 통해 자체 진화 시스템의 안전성 저하 현상을 확인

### 🧑‍💻 개발자 관점
LLM 에이전트 기반 시스템 개발 시 자체 진화 메커니즘 설계에 대한 근본적인 한계를 인지하고, 안전성 확보를 위한 추가적인 장치(외부 감독, 안전 유지 메커니즘)를 고려해야 한다.

### 🚀 바로 실험할 액션
- 자체 진화 에이전트 시스템의 안전성 평가 지표 개발
- 외부 감독 메커니즘이 안전성 유지에 미치는 영향 실험
- 새로운 안전 유지 메커니즘(예: 가치 정렬 강화) 실험

### ⚠️ 리스크/한계
- 실험 환경이 실제 배포 환경과 다를 수 있음
- 안전성 측정 기준이 주관적일 수 있음

### 🧭 불확실성 메모
초록 정보만으로 판단하였으므로, 실제 논문 내용과 차이가 있을 수 있습니다.

### 📝 초록 기반 상세 설명
LLM 기반의 멀티 에이전트 시스템은 확장 가능한 집단 지능과 자체 진화를 위한 유망한 패러다임을 제공하지만, 완전한 폐쇄 루프 내에서 지속적인 자체 개선과 강력한 안전성 유지를 동시에 달성하기는 어렵다. 본 연구에서는 자체 진화, 완전한 격리, 안전성 불변의 세 가지 조건을 동시에 만족하는 에이전트 시스템은 불가능함을 이론 및 실험적으로 입증한다. 정보 이론적 프레임워크를 사용하여 안전성을 인간 가치 분포로부터의 발산 정도로 공식화하고, 격리된 자체 진화는 통계적 사각 지대를 유발하여 시스템의 안전성 정렬이 불가역적으로 저하됨을 보인다. Moltbook이라는 오픈 에이전트 커뮤니티와 두 개의 폐쇄형 자체 진화 시스템에서 얻은 경험적 및 질적 결과는 이론적 예측과 일치하며, 안전성 저하 문제를 완화하기 위한 몇 가지 해결책을 제시한다.


---

## 2. [Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models](https://huggingface.co/papers/2602.12036)
**Upvotes**: 85 | **도입 난이도**: 중 | **신뢰도**: 중

**태그**: LLM, Reinforcement Learning, Prompting, Reasoning, Evaluation

![Thumbnail](images/Composition-RL_Compose_Your_Verifiable_Prompts_for_Reinforcement_Learning_of_Large_Language_Models_img.jpg)

### 📌 한 줄 요약
Composition-RL은 쉬운 프롬프트를 활용하여 LLM의 추론 능력을 향상시키는 간단하면서도 효과적인 강화 학습 방법으로, 다양한 도메인에 적용 가능하다.

### 🔑 핵심 포인트
- 통과율 1인 쉬운 프롬프트를 활용하는 Composition-RL 방법론 제안
- 프롬프트 조합을 통해 LLM의 추론 능력 향상
- 커리큘럼 학습 및 교차 도메인 적용 가능성을 입증

### 🧑‍💻 개발자 관점
기존에 활용도가 낮았던 쉬운 프롬프트를 활용하여 LLM의 성능을 개선할 수 있으며, 특히 도메인 간 결합을 통해 새로운 기능을 창출할 가능성을 제시한다.

### 🚀 바로 실험할 액션
- 자체 데이터셋에서 쉬운 프롬프트와 어려운 프롬프트의 비율을 분석
- Composition-RL을 적용하여 LLM의 성능 향상 가능성 확인
- 다양한 도메인의 프롬프트를 조합하여 새로운 기능 개발 시도

### ⚠️ 리스크/한계
- 조합되는 문제의 성격에 따라 성능 향상 효과가 달라질 수 있음
- 조합 과정에서 발생하는 추가적인 계산 비용 고려 필요

### 🧭 불확실성 메모
초록만으로는 Composition-RL의 구체적인 구현 방식과 성능 향상 정도를 정확히 파악하기 어렵다.

### 📝 초록 기반 상세 설명
최근 RLVR 연구는 통과율이 0인 어려운 프롬프트에 집중하는 경향이 있지만, 학습이 진행될수록 통과율이 1인 쉬운 프롬프트도 증가하여 효과적인 데이터 크기가 줄어드는 문제가 발생한다. 이를 해결하기 위해 본 논문에서는 Composition-RL이라는 새로운 방법을 제안한다. Composition-RL은 여러 문제를 조합하여 새로운 검증 가능한 질문을 생성하고, 이를 강화 학습 훈련에 활용한다. 실험 결과, 4B에서 30B에 이르는 다양한 모델 크기에서 Composition-RL이 기존 방식보다 추론 능력을 일관되게 향상시켰으며, 점진적으로 조합 깊이를 늘리는 커리큘럼 방식을 통해 성능을 더욱 높일 수 있었다. 또한, Composition-RL은 서로 다른 도메인의 프롬프트를 조합하여 교차 도메인 강화 학습의 효과를 높일 수 있다.


---

## 3. [DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing](https://huggingface.co/papers/2602.12205)
**Upvotes**: 67 | **도입 난이도**: 중 | **신뢰도**: 중

**태그**: Multimodal, Image Generation, Image Editing, VLM, Reinforcement Learning, RAG, Reasoning, Vision, Benchmark, Safety

![Thumbnail](images/DeepGen_1.0_A_Lightweight_Unified_Multimodal_Model_for_Advancing_Image_Generation_and_Editing_img.jpg)

### 📌 한 줄 요약
5B 파라미터의 경량 모델 DeepGen 1.0은 이미지 생성 및 편집 작업에서 대형 모델을 능가하는 성능을 보여주며, 오픈소스를 통해 접근성을 높였습니다.

### 🔑 핵심 포인트
- 5B 파라미터의 경량 unified multimodal 모델 DeepGen 1.0 제시
- Stacked Channel Bridging (SCB)을 통한 의미 이해 및 제어 능력 향상
- 데이터 중심 학습 전략 및 강화 학습을 통한 성능 향상

### 🧑‍💻 개발자 관점
기존 대형 모델의 높은 비용과 배포 문제를 해결하고, 소규모 리소스로도 강력한 이미지 생성 및 편집 기능을 활용할 수 있게 합니다. 오픈 소스 코드를 통해 빠르게 실험하고 적용할 수 있습니다.

### 🚀 바로 실험할 액션
- DeepGen 1.0 모델 다운로드 및 설치
- 제공된 예제 코드를 사용하여 이미지 생성 및 편집 실험
- SCB 모듈을 기존 모델에 적용하여 성능 개선 시도

### ⚠️ 리스크/한계
- 50M 샘플로 학습되었기에 특정 도메인에 대한 일반화 성능이 부족할 수 있음
- 경량 모델의 특성상 극도로 복잡한 시나리오에서는 성능 저하가 발생할 수 있음

### 🧭 불확실성 메모
초록에 제시된 정보만으로는 모델의 모든 기능을 완벽하게 파악하기 어렵습니다.

### 📝 초록 기반 상세 설명
최근 이미지 생성 및 편집을 위한 통합 멀티모달 모델은 막대한 파라미터 크기로 인해 학습 비용과 배포 부담이 컸습니다. DeepGen 1.0은 5B 파라미터의 경량 모델로, Stacked Channel Bridging (SCB)을 통해 의미 이해 능력과 세밀한 제어 능력을 향상시켰습니다. 데이터 중심 학습 전략은 VLM과 DiT 표현을 동기화하고, 다양한 작업을 공동으로 학습하며, 강화 학습을 통해 생성 품질과 인간 선호도와의 일치도를 높입니다. DeepGen 1.0은 적은 데이터로도 여러 벤치마크에서 뛰어난 성능을 보이며, 오픈소스를 통해 연구 접근성을 높였습니다.


---

## 4. [Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation](https://huggingface.co/papers/2602.12125)
**Upvotes**: 54 | **도입 난이도**: 중 | **신뢰도**: 중

**태그**: Distillation, Reinforcement Learning, Code Generation, Math Reasoning, Reasoning

![Thumbnail](images/Learning_beyond_Teacher_Generalized_On-Policy_Distillation_with_Reward_Extrapolation_img.jpg)

### 📌 한 줄 요약
온-폴리시 증류(OPD)를 개선하는 새로운 방법론인 G-OPD 프레임워크를 제안하고, 특히 보상 외삽(reward extrapolation)을 통해 학생 모델이 교사 모델을 능가하는 결과를 얻을 수 있음을 보임.

### 🔑 핵심 포인트
- OPD가 KL-제약 강화 학습의 특수한 경우임을 이론적으로 증명
- 보상 스케일링 인자를 도입하여 OPD를 일반화한 G-OPD 프레임워크 제안
- 보상 외삽(ExOPD)을 통해 학생 모델이 교사 모델을 능가하는 성능 향상 달성

### 🧑‍💻 개발자 관점
모델 증류를 통해 더 작은 모델로 성능을 유지하거나 향상시키는 데 활용될 수 있으며, 특히 도메인 전문가 모델의 지식을 통합하거나, 모델 성능을 극대화하는 데 유용할 수 있다.

### 🚀 바로 실험할 액션
- 기존 OPD 파이프라인에 보상 외삽(ExOPD) 적용해보기
- 강한 교사 모델에서 약한 학생 모델로 증류 시, 교사 모델의 RL 이전 상태를 참조 모델로 활용하는 보상 수정 방식 실험
- 다양한 보상 스케일링 인자 값을 실험하여 최적의 값 찾기

### ⚠️ 리스크/한계
- 교사 모델의 RL 이전 상태 접근이 어려울 수 있음
- 보상 스케일링 인자 최적값은 task에 따라 달라질 수 있음

### 🧭 불확실성 메모
초록만으로는 구체적인 실험 설정 및 데이터셋에 대한 정보가 부족하여 일반화에 한계가 있을 수 있다.

### 📝 초록 기반 상세 설명
온-폴리시 증류(OPD)는 학생 모델의 성능 향상에 효과적이지만, 본 연구에서는 OPD가 특정 조건의 강화 학습(RL)의 특수한 경우임을 이론적으로 밝히고, 이를 일반화한 G-OPD 프레임워크를 제안한다. G-OPD는 유연한 참조 모델과 보상 스케일링 인자를 도입하여 표준 OPD의 한계를 극복한다. 수학 추론 및 코드 생성 실험 결과, 보상 스케일링 인자를 1보다 크게 설정하는 보상 외삽(ExOPD)이 표준 OPD보다 성능이 우수하며, 특히 여러 도메인 전문가의 지식을 통합하는 데 효과적임을 확인했다. 또한, 강한 교사 모델에서 약한 학생 모델로 증류할 때, 교사 모델의 RL 이전 상태를 참조 모델로 사용하는 보상 수정 방식이 더욱 정확한 보상 신호를 제공하여 성능을 향상시킬 수 있음을 발견했다. 이 연구는 OPD 연구에 새로운 방향을 제시한다.


---

## 5. [MOSS-Audio-Tokenizer: Scaling Audio Tokenizers for Future Audio Foundation Models](https://huggingface.co/papers/2602.10934)
**Upvotes**: 44 | **도입 난이도**: 중 | **신뢰도**: 중

**태그**: Audio, Tokenizer, Transformer, TTS, Foundation Model, RAG, Distillation

![Thumbnail](images/MOSS-Audio-Tokenizer_Scaling_Audio_Tokenizers_for_Future_Audio_Foundation_Models_img.jpg)

### 📌 한 줄 요약
Transformer 기반의 대규모 오디오 토크나이저인 MOSS-Audio-Tokenizer를 개발하여, 다양한 오디오 도메인에서 기존 코덱을 능가하는 성능을 보였고, 고품질 오디오 생성이 가능해짐.

### 🔑 핵심 포인트
- 순수 Transformer 기반의 CAT 아키텍처를 제안하여 end-to-end 오디오 토크나이저 학습
- 16억 파라미터의 MOSS-Audio-Tokenizer를 개발하여 다양한 오디오 도메인에서 SOTA 달성
- MOSS-Audio-Tokenizer를 활용하여 고품질의 autoregressive TTS 모델 구축

### 🧑‍💻 개발자 관점
MOSS-Audio-Tokenizer는 오디오 관련 task에서 더 나은 성능과 유연성을 제공하며, 특히 오디오 생성 및 음성 합성과 같은 분야에서 활용 가능성이 높다. 기존 파이프라인의 복잡성을 줄이고, 더 강력한 오디오 모델을 구축하는 데 기여할 수 있다.

### 🚀 바로 실험할 액션
- MOSS-Audio-Tokenizer를 다운로드하여 다양한 오디오 데이터셋에서 성능 테스트
- 자체 오디오 데이터셋으로 MOSS-Audio-Tokenizer를 fine-tuning하여 특정 task에 적용
- MOSS-Audio-Tokenizer를 활용하여 새로운 오디오 생성 모델 개발

### ⚠️ 리스크/한계
- 대규모 모델이므로 학습 및 추론에 상당한 컴퓨팅 자원이 필요할 수 있음
- 일부 특수한 오디오 도메인에서는 fine-tuning 없이 일반화 성능이 떨어질 수 있음

### 🧭 불확실성 메모
초록만으로는 모델의 학습 데이터 구성 및 편향, 그리고 특정 도메인에 대한 일반화 성능을 정확히 파악하기 어렵다.

### 📝 초록 기반 상세 설명
최근 오디오 처리 및 생성 분야에서 이산적인 오디오 토크나이저가 중요해지고 있지만, 기존 방법들은 고정된 inductive bias로 인해 재구성 충실도가 낮고 확장성이 제한되는 문제가 있었다. 본 논문에서는 Transformer 기반의 CAT 아키텍처를 제안하여 인코더, 양자화기, 디코더를 처음부터 공동으로 최적화함으로써 이러한 문제를 해결하고자 한다. CAT 아키텍처를 기반으로 16억 개의 파라미터를 가진 대규모 오디오 토크나이저인 MOSS-Audio-Tokenizer를 개발하여 3백만 시간 분량의 다양한 오디오 데이터로 사전 훈련했다. 그 결과, 다양한 오디오 도메인에서 기존 코덱보다 우수한 성능을 보였으며, 특히 autoregressive TTS 모델을 통해 기존 모델을 능가하는 성능을 달성했다. MOSS-Audio-Tokenizer는 차세대 오디오 파운데이션 모델을 위한 통합되고 확장 가능한 인터페이스를 제공한다.


---

