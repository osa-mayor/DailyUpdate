{
  "source": "huggingface_papers",
  "date": "2026-02-16",
  "generated_at": "2026-02-17T12:42:16.892941+09:00",
  "count": 5,
  "chat_message": "ğŸ”¥ ì˜¤ëŠ˜ì˜ ë…¼ë¬¸\n\nğŸ“ 1. Less is Enough: Synthesizing Diverse Data in Feature Space of LLMs\nğŸ“ ìš”ì•½: LLMì˜ downstream ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´, sparse autoencoder ê¸°ë°˜ì˜ feature activation coverage(FAC)ë¼ëŠ” ìƒˆë¡œìš´ ë°ì´í„° ë‹¤ì–‘ì„± ì¸¡ì • ì§€í‘œì™€ ë°ì´í„° í•©ì„± í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ê³ , ì´ë¥¼ í†µí•´ ì ì€ ë°ì´í„°ë¡œë„ ì„±ëŠ¥ í–¥ìƒì„ ì´ëŒì–´ëƒ„.\nğŸ”— Hugging Face: https://huggingface.co/papers/2602.10388\nğŸ“„ arXiv: https://arxiv.org/abs/2602.10388\n\nğŸ“ 2. SQuTR: A Robustness Benchmark for Spoken Query to Text Retrieval under Acoustic Noise\nğŸ“ ìš”ì•½: SQuTR ë²¤ì¹˜ë§ˆí¬ëŠ” ìŒì„± ì§ˆì˜-í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ë…¸ì´ì¦ˆ í™˜ê²½ì—ì„œì˜ ì„±ëŠ¥ ì €í•˜ë¥¼ ì§„ë‹¨í•˜ê³  ê°œì„ í•˜ëŠ”ë° ìœ ìš©í•˜ë©°, ì‹¤ì œ ì‚¬ìš©ì í™˜ê²½ì—ì„œì˜ ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nğŸ”— Hugging Face: https://huggingface.co/papers/2602.12783\nğŸ“„ arXiv: https://arxiv.org/abs/2602.12783\n\nğŸ“ 3. MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs\nğŸ“ ìš”ì•½: MedXIAOHEëŠ” ì˜ë£Œ ë¶„ì•¼ì˜ ì‹œê°-ì–¸ì–´ ëª¨ë¸ë¡œ, ë‹¤ì–‘í•œ ì˜ë£Œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœê³  ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê³  íì‡„í˜• ì‹œìŠ¤í…œì„ ëŠ¥ê°€í•˜ë©°, ì§€ì‹ í™•ì¥, ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒ, ì‹ ë¢°ì„± ê°œì„ ì„ í†µí•´ ì‹¤ì œ ì„ìƒ ì ìš© ê°€ëŠ¥ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.\nğŸ”— Hugging Face: https://huggingface.co/papers/2602.12705\nğŸ“„ arXiv: https://arxiv.org/abs/2602.12705\n\nì¶œì²˜: Hugging Face Papers\nhttps://huggingface.co/papers\n\nğŸ‘‰ ì „ì²´ ë¦¬í¬íŠ¸\nhttps://github.com/osa-mayor/DailyUpdate/blob/main/Papers/papers_2026-02-16.md",
  "items": [
    {
      "rank": 1,
      "title": "Less is Enough: Synthesizing Diverse Data in Feature Space of LLMs",
      "paper_id": "2602.10388",
      "url": "https://huggingface.co/papers/2602.10388",
      "arxiv_url": "https://arxiv.org/abs/2602.10388",
      "upvotes": 202,
      "summary": "LLMì˜ downstream ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´, sparse autoencoder ê¸°ë°˜ì˜ feature activation coverage(FAC)ë¼ëŠ” ìƒˆë¡œìš´ ë°ì´í„° ë‹¤ì–‘ì„± ì¸¡ì • ì§€í‘œì™€ ë°ì´í„° í•©ì„± í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ê³ , ì´ë¥¼ í†µí•´ ì ì€ ë°ì´í„°ë¡œë„ ì„±ëŠ¥ í–¥ìƒì„ ì´ëŒì–´ëƒ„.",
      "key_points": [
        "Feature Activation Coverage (FAC)ë¼ëŠ” ìƒˆë¡œìš´ ë°ì´í„° ë‹¤ì–‘ì„± ì¸¡ì • ì§€í‘œ ì œì‹œ",
        "Sparse autoencoder ê¸°ë°˜ì˜ ë‹¤ì–‘ì„± ê¸°ë°˜ ë°ì´í„° í•©ì„± í”„ë ˆì„ì›Œí¬ (FAC Synthesis) ì œì•ˆ",
        "ë‹¤ì–‘í•œ LLM ëª¨ë¸ ê°„ì— ê³µìœ  ê°€ëŠ¥í•œ feature space ì¡´ì¬ í™•ì¸"
      ],
      "tags": [
        "Fine-tuning",
        "Data Augmentation",
        "LLM",
        "Interpretability",
        "RAG"
      ],
      "confidence": "ìƒ",
      "adoption_complexity": "ì¤‘",
      "practical_relevance": "LLM fine-tuning ì‹œ ë°ì´í„°ì…‹ êµ¬ì¶• ë¹„ìš©ì„ ì¤„ì´ê³ , ì ì€ ë°ì´í„°ë¡œë„ ëª¨ë¸ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ì œì‹œí•˜ë©°, ëª¨ë¸ ê°„ knowledge transfer ì „ëµ ìˆ˜ë¦½ì— í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.",
      "recommended_actions": [
        "FAC metricì„ í™œìš©í•˜ì—¬ í˜„ì¬ fine-tuning ë°ì´í„°ì…‹ì˜ ë‹¤ì–‘ì„± ë¶„ì„",
        "Sparse autoencoderë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì˜ ë¶€ì¡±í•œ feature íŒŒì•… ë° ë³´ì™„",
        "FAC Synthesis í”„ë ˆì„ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ synthetic ë°ì´í„° ìƒì„± ë° fine-tuning ì ìš©"
      ],
      "risks_and_limits": [
        "Sparse autoencoder í•™ìŠµ ë° interpretable feature space ì •ì˜ì˜ ì–´ë ¤ì›€",
        "Synthetic ë°ì´í„°ì˜ í˜„ì‹¤ì„± ë° ì¼ë°˜í™” ì„±ëŠ¥ì— ëŒ€í•œ ì¶”ê°€ ê²€ì¦ í•„ìš”"
      ],
      "repeated_in_window": false,
      "repeated_days_ago": null
    },
    {
      "rank": 2,
      "title": "SQuTR: A Robustness Benchmark for Spoken Query to Text Retrieval under Acoustic Noise",
      "paper_id": "2602.12783",
      "url": "https://huggingface.co/papers/2602.12783",
      "arxiv_url": "https://arxiv.org/abs/2602.12783",
      "upvotes": 134,
      "summary": "SQuTR ë²¤ì¹˜ë§ˆí¬ëŠ” ìŒì„± ì§ˆì˜-í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ë…¸ì´ì¦ˆ í™˜ê²½ì—ì„œì˜ ì„±ëŠ¥ ì €í•˜ë¥¼ ì§„ë‹¨í•˜ê³  ê°œì„ í•˜ëŠ”ë° ìœ ìš©í•˜ë©°, ì‹¤ì œ ì‚¬ìš©ì í™˜ê²½ì—ì„œì˜ ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "key_points": [
        "ì‹¤ì œ í™˜ê²½ ë…¸ì´ì¦ˆë¥¼ ë°˜ì˜í•œ ëŒ€ê·œëª¨ ìŒì„± ì§ˆì˜-í…ìŠ¤íŠ¸ ê²€ìƒ‰ Robustness ë²¤ì¹˜ë§ˆí¬ SQuTR ì œì‹œ",
        "ë‹¤ì–‘í•œ ìŒì„± í”„ë¡œí•„ ë° ë…¸ì´ì¦ˆ í™˜ê²½ì„ ê²°í•©í•˜ì—¬ ì¬í˜„ ê°€ëŠ¥í•œ í‰ê°€ í™˜ê²½ êµ¬ì¶•",
        "ê¸°ì¡´ ì‹œìŠ¤í…œì˜ Robustness ì·¨ì•½ì ì„ ë¶„ì„í•˜ê³  í–¥í›„ ì—°êµ¬ ë°©í–¥ ì œì‹œ"
      ],
      "tags": [
        "Speech Recognition",
        "Information Retrieval",
        "Benchmark",
        "Robustness",
        "Noise",
        "RAG",
        "Evaluation"
      ],
      "confidence": "ìƒ",
      "adoption_complexity": "ì¤‘",
      "practical_relevance": "ì‹¤ì œ ì„œë¹„ìŠ¤ í™˜ê²½ì—ì„œ ë°œìƒí•˜ëŠ” ë‹¤ì–‘í•œ ë…¸ì´ì¦ˆ ì¡°ê±´ì—ì„œ ìŒì„± ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ê°œì„ í•˜ëŠ” ë° ì§ì ‘ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬ìš©ì ê²½í—˜ í–¥ìƒì— ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "recommended_actions": [
        "SQuTR ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ê¸°ì¡´ ìŒì„± ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ë…¸ì´ì¦ˆ Robustness í‰ê°€",
        "SQuTR ë²¤ì¹˜ë§ˆí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±° ë˜ëŠ” ìŒì„± í–¥ìƒ ê¸°ìˆ  ì ìš© í›„ ì„±ëŠ¥ ê°œì„  íš¨ê³¼ í™•ì¸",
        "ìƒˆë¡œìš´ ìŒì„± ê²€ìƒ‰ ëª¨ë¸ ê°œë°œ ì‹œ SQuTR ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ Robustnessë¥¼ í‰ê°€í•˜ê³  ê°œì„ í•˜ëŠ” ê³¼ì •ì— ì ìš©"
      ],
      "risks_and_limits": [
        "í•©ì„± ìŒì„± ë°ì´í„°ê°€ ì‹¤ì œ ìŒì„± ë°ì´í„°ì™€ ì°¨ì´ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë©°, ì¼ë¶€ íŠ¹ìˆ˜í•œ ë…¸ì´ì¦ˆ í™˜ê²½ì€ ë°˜ì˜ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ",
        "SQuTR ë²¤ì¹˜ë§ˆí¬ëŠ” íŠ¹ì • ì–¸ì–´(ì˜ì–´, ì¤‘êµ­ì–´) ë° ë„ë©”ì¸ì— í¸í–¥ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŒ"
      ],
      "repeated_in_window": false,
      "repeated_days_ago": null
    },
    {
      "rank": 3,
      "title": "MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs",
      "paper_id": "2602.12705",
      "url": "https://huggingface.co/papers/2602.12705",
      "arxiv_url": "https://arxiv.org/abs/2602.12705",
      "upvotes": 56,
      "summary": "MedXIAOHEëŠ” ì˜ë£Œ ë¶„ì•¼ì˜ ì‹œê°-ì–¸ì–´ ëª¨ë¸ë¡œ, ë‹¤ì–‘í•œ ì˜ë£Œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœê³  ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê³  íì‡„í˜• ì‹œìŠ¤í…œì„ ëŠ¥ê°€í•˜ë©°, ì§€ì‹ í™•ì¥, ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒ, ì‹ ë¢°ì„± ê°œì„ ì„ í†µí•´ ì‹¤ì œ ì„ìƒ ì ìš© ê°€ëŠ¥ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.",
      "key_points": [
        "Entity-aware continual pretrainingì„ í†µí•œ ì§€ì‹ ì»¤ë²„ë¦¬ì§€ í™•ì¥",
        "ê°•í™” í•™ìŠµ ë° Tool-augmented agentic trainingì„ í†µí•œ ì˜ë£Œ ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒ",
        "ì‚¬ìš©ì ì„ í˜¸ë„, ì¦ê±° ê¸°ë°˜ ì¶”ë¡ , ë‚®ì€ í™˜ê°ì˜ ê¸´ ë³´ê³ ì„œ ìƒì„±ì„ í†µí•œ ì‹ ë¢°ì„± ê°œì„ "
      ],
      "tags": [
        "MLLM",
        "Medical AI",
        "Reasoning",
        "Reinforcement Learning",
        "Pretraining",
        "Agent",
        "RAG",
        "Multimodal",
        "Vision",
        "Benchmark",
        "Evaluation"
      ],
      "confidence": "ìƒ",
      "adoption_complexity": "ì¤‘",
      "practical_relevance": "ì˜ë£Œ ë¶„ì•¼ì— íŠ¹í™”ëœ MLLMì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ë ˆì‹œí”¼ì™€ ê°™ì€ ì—­í• ì„ í•˜ë©°, íŠ¹íˆ ì§€ì‹ í™•ì¥, ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒ, ì‹ ë¢°ì„± ê°œì„ ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ë°©ë²•ì„ ì œì‹œí•˜ì—¬ ì‹¤ì œ ì˜ë£Œ ì„œë¹„ìŠ¤ ê°œë°œì— ì°¸ê³ í•  ë§Œí•©ë‹ˆë‹¤.",
      "recommended_actions": [
        "Entity-aware continual pretrainingì„ ìì‚¬ì˜ ì˜ë£Œ ë°ì´í„°ì— ì ìš©í•´ë³´ê¸°",
        "ê°•í™” í•™ìŠµ ê¸°ë°˜ì˜ ì¶”ë¡  ì—”ì§„ì„ êµ¬ì¶•í•˜ê³  ì˜ë£Œ ë°ì´í„°ì— ì ìš©í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ ì‹œë„",
        "ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°˜ì˜í•˜ëŠ” ë³´ê³ ì„œ ìƒì„± ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„"
      ],
      "risks_and_limits": [
        "ì‹¤ì œ ì„ìƒ í™˜ê²½ì—ì„œì˜ ì„±ëŠ¥ ê²€ì¦ í•„ìš”",
        "ëª¨ë¸ì˜ í•´ì„ ê°€ëŠ¥ì„±ê³¼ ì„¤ëª… ê°€ëŠ¥ì„± í™•ë³´ê°€ ì¤‘ìš”"
      ],
      "repeated_in_window": false,
      "repeated_days_ago": null
    },
    {
      "rank": 4,
      "title": "Zooming without Zooming: Region-to-Image Distillation for Fine-Grained Multimodal Perception",
      "paper_id": "2602.11858",
      "url": "https://huggingface.co/papers/2602.11858",
      "arxiv_url": "https://arxiv.org/abs/2602.11858",
      "upvotes": 50,
      "summary": "MLLMì˜ fine-grained ì¸ì‹ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´, inference ì‹œì ì— zoomingí•˜ëŠ” ëŒ€ì‹  í•™ìŠµ ì‹œì ì— region-grounded supervisionì„ í†µí•´ single-glance ì¸ì‹ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” Region-to-Image Distillation ë°©ë²•ë¡ ì„ ì œì•ˆí•˜ë©°, fine-grained perception benchmarkì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„.",
      "key_points": [
        "Region-to-Image Distillation: inference ì‹œì  zoomingì„ training ì‹œì ìœ¼ë¡œ ì˜®ê²¨ single-glance fine-grained perception ëŠ¥ë ¥ í–¥ìƒ",
        "ZoomBench: fine-grained perception ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ hybrid-annotated VQA benchmark ì œì‹œ",
        "Fine-grained perception ë° ì¼ë°˜ multimodal cognition benchmarkì—ì„œ SOTA ì„±ëŠ¥ ë‹¬ì„±"
      ],
      "tags": [
        "Agent",
        "Vision",
        "Distillation",
        "Fine-grained perception",
        "MLLM",
        "Reasoning",
        "Multimodal",
        "Benchmark",
        "Evaluation",
        "Inference"
      ],
      "confidence": "ìƒ",
      "adoption_complexity": "ì¤‘",
      "practical_relevance": "ê¸°ì¡´ MLLMì˜ ë¯¸ì„¸í•œ ì¸ì‹ ëŠ¥ë ¥ ë¶€ì¡± ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  inference latencyë¥¼ ì¤„ì—¬ ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš© ê°€ëŠ¥ì„±ì„ ë†’ì„. íŠ¹íˆ ì‘ì€ ê°ì²´ë‚˜ ë””í…Œì¼ì´ ì¤‘ìš”í•œ ì„œë¹„ìŠ¤(ì˜ë£Œ, ì œì¡° ë“±)ì—ì„œ ìœ ìš©í•  ìˆ˜ ìˆë‹¤.",
      "recommended_actions": [
        "ì œê³µëœ Github ë ˆí¬ì§€í† ë¦¬ì˜ ì½”ë“œë¥¼ ì‚´í´ë³´ê³ , ê¸°ì¡´ ëª¨ë¸ì— ì ìš© ê°€ëŠ¥ì„± ê²€í† ",
        "ZoomBench ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì˜ fine-grained perception ì„±ëŠ¥ í‰ê°€",
        "ìì²´ ë°ì´í„°ì…‹ì— Region-to-Image Distillation ë°©ë²•ë¡  ì ìš© ë° ì„±ëŠ¥ ë¹„êµ"
      ],
      "risks_and_limits": [
        "Teacher ëª¨ë¸ì˜ ì„±ëŠ¥ì— í¬ê²Œ ì˜ì¡´ì ì´ë©°, teacher ëª¨ë¸ì˜ biasê°€ student ëª¨ë¸ì— ì „ì´ë  ìˆ˜ ìˆìŒ",
        "ZoomBench ë°ì´í„°ì…‹ì˜ íŠ¹ì„±ìƒ íŠ¹ì • fine-grained perception taskì—ë§Œ íš¨ê³¼ì ì¼ ìˆ˜ ìˆìœ¼ë©°, ì¼ë°˜ì ì¸ fine-grained perceptionì— ëŒ€í•œ ì¼ë°˜í™” ì„±ëŠ¥ì€ ë¶ˆí™•ì‹¤í•¨"
      ],
      "repeated_in_window": false,
      "repeated_days_ago": null
    },
    {
      "rank": 5,
      "title": "OneVision-Encoder: Codec-Aligned Sparsity as a Foundational Principle for Multimodal Intelligence",
      "paper_id": "2602.08683",
      "url": "https://huggingface.co/papers/2602.08683",
      "arxiv_url": "https://arxiv.org/abs/2602.08683",
      "upvotes": 39,
      "summary": "ë™ì˜ìƒ ì½”ë±ì˜ ì •ë³´ ì´ë¡ ì  ì›ë¦¬ë¥¼ í™œìš©í•˜ì—¬ ì‹œê° ì •ë³´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì••ì¶•í•˜ê³  ì´í•´í•˜ëŠ” ìƒˆë¡œìš´ ë¹„ì „ ì¸ì½”ë” ì•„í‚¤í…ì²˜(OneVision-Encoder)ë¥¼ ì œì•ˆ, ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒ ë° íš¨ìœ¨ì„± ì¦ê°€ë¥¼ ë‹¬ì„±í•¨.",
      "key_points": [
        "ë™ì˜ìƒ ì½”ë± ì›ë¦¬ë¥¼ í™œìš©í•œ ìƒˆë¡œìš´ ë¹„ì „ ì¸ì½”ë” ì•„í‚¤í…ì²˜ (OneVision-Encoder) ì œì•ˆ",
        "ì½”ë± íŒ¨ì¹˜í™”ë¥¼ í†µí•´ ì •ë³´ëŸ‰ì´ ë§ì€ ì˜ì—­ì— ì§‘ì¤‘, ì—°ì‚° íš¨ìœ¨ì„± ê·¹ëŒ€í™”",
        "ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ ì ì€ ì—°ì‚°ëŸ‰ê³¼ ë°ì´í„°ë¡œ ë” ë‚˜ì€ ì„±ëŠ¥ ë‹¬ì„±"
      ],
      "tags": [
        "Vision",
        "Compression",
        "Codec",
        "Efficiency",
        "Sparsity",
        "RAG",
        "Reasoning",
        "Multimodal",
        "Video",
        "Benchmark",
        "Optimization"
      ],
      "confidence": "ì¤‘",
      "adoption_complexity": "ì¤‘",
      "practical_relevance": "ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œ ë¹„ë””ì˜¤/ì´ë¯¸ì§€ ì´í•´ ëª¨ë¸ì˜ íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ê³  ì‹¶ì„ ë•Œ, OneVision-Encoderì˜ ì½”ë± ê¸°ë°˜ í¬ì†Œì„± ì ‘ê·¼ ë°©ì‹ì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì˜ ì—°ì‚° ë¹„ìš©ì„ ì¤„ì´ë©´ì„œë„ ì„±ëŠ¥ì„ ìœ ì§€í•˜ê±°ë‚˜ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤.",
      "recommended_actions": [
        "OneVision-Encoderì˜ ì½”ë± íŒ¨ì¹˜í™” ë°©ì‹ì„ ê¸°ì¡´ ëª¨ë¸ì— ì ìš©í•˜ì—¬ ì„±ëŠ¥ ë° íš¨ìœ¨ì„± ë³€í™” ê´€ì°°",
        "ìì²´ ë°ì´í„°ì…‹ì— OneVision-Encoderë¥¼ íŒŒì¸íŠœë‹í•˜ì—¬ íŠ¹ì • ë„ë©”ì¸ì—ì„œì˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸",
        "OneVision-Encoderë¥¼ LLMê³¼ í†µí•©í•˜ì—¬ ë©€í‹°ëª¨ë‹¬ íƒœìŠ¤í¬ì—ì„œì˜ ì„±ëŠ¥ ë¹„êµ"
      ],
      "risks_and_limits": [
        "ì½”ë± ê¸°ë°˜ í¬ì†Œì„± ë°©ì‹ì´ íŠ¹ì • ìœ í˜•ì˜ ë¹„ë””ì˜¤/ì´ë¯¸ì§€ì—ë§Œ íš¨ê³¼ì ì¼ ìˆ˜ ìˆìŒ",
        "OneVision-Encoderì˜ êµ¬í˜„ ë³µì¡ë„ê°€ ë†’ì„ ìˆ˜ ìˆìœ¼ë©°, ì¶”ê°€ì ì¸ ì—”ì§€ë‹ˆì–´ë§ ë…¸ë ¥ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ"
      ],
      "repeated_in_window": false,
      "repeated_days_ago": null
    }
  ]
}