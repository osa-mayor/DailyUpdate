{
  "source": "huggingface_papers",
  "date": "2026-02-16",
  "generated_at": "2026-02-17T05:29:53.941745+09:00",
  "count": 5,
  "chat_message": "ğŸ”¥ ì˜¤ëŠ˜ì˜ ë…¼ë¬¸\n\nğŸ“ 1. Less is Enough: Synthesizing Diverse Data in Feature Space of LLMs\nğŸ“ ìš”ì•½: ìš”ì•½ ì •ë³´ ì—†ìŒ\nğŸ”— Hugging Face: https://huggingface.co/papers/2602.10388\nğŸ“„ arXiv: https://arxiv.org/abs/2602.10388\n\nğŸ“ 2. SQuTR: A Robustness Benchmark for Spoken Query to Text Retrieval under Acoustic Noise\nğŸ“ ìš”ì•½: ìš”ì•½ ì •ë³´ ì—†ìŒ\nğŸ”— Hugging Face: https://huggingface.co/papers/2602.12783\nğŸ“„ arXiv: https://arxiv.org/abs/2602.12783\n\nğŸ“ 3. MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs\nğŸ“ ìš”ì•½: ìš”ì•½ ì •ë³´ ì—†ìŒ\nğŸ”— Hugging Face: https://huggingface.co/papers/2602.12705\nğŸ“„ arXiv: https://arxiv.org/abs/2602.12705\n\nì¶œì²˜: Hugging Face Papers\nhttps://huggingface.co/papers\n\nğŸ‘‰ ì „ì²´ ë¦¬í¬íŠ¸\nhttps://github.com/osa-mayor/DailyUpdate/blob/main/Papers/papers_2026-02-16.md",
  "items": [
    {
      "rank": 1,
      "title": "Less is Enough: Synthesizing Diverse Data in Feature Space of LLMs",
      "paper_id": "2602.10388",
      "url": "https://huggingface.co/papers/2602.10388",
      "arxiv_url": "https://arxiv.org/abs/2602.10388",
      "upvotes": 195,
      "summary": null,
      "key_points": [],
      "tags": [
        "RAG"
      ],
      "confidence": "ì¤‘",
      "adoption_complexity": "ì¤‘",
      "practical_relevance": null,
      "recommended_actions": [],
      "risks_and_limits": [],
      "repeated_in_window": false,
      "repeated_days_ago": null
    },
    {
      "rank": 2,
      "title": "SQuTR: A Robustness Benchmark for Spoken Query to Text Retrieval under Acoustic Noise",
      "paper_id": "2602.12783",
      "url": "https://huggingface.co/papers/2602.12783",
      "arxiv_url": "https://arxiv.org/abs/2602.12783",
      "upvotes": 131,
      "summary": null,
      "key_points": [],
      "tags": [
        "RAG",
        "Benchmark",
        "Evaluation"
      ],
      "confidence": "ì¤‘",
      "adoption_complexity": "ì¤‘",
      "practical_relevance": null,
      "recommended_actions": [],
      "risks_and_limits": [],
      "repeated_in_window": false,
      "repeated_days_ago": null
    },
    {
      "rank": 3,
      "title": "MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs",
      "paper_id": "2602.12705",
      "url": "https://huggingface.co/papers/2602.12705",
      "arxiv_url": "https://arxiv.org/abs/2602.12705",
      "upvotes": 54,
      "summary": null,
      "key_points": [],
      "tags": [
        "Agent",
        "RAG",
        "Reasoning",
        "Multimodal",
        "Vision",
        "Benchmark",
        "Evaluation"
      ],
      "confidence": "ì¤‘",
      "adoption_complexity": "ì¤‘",
      "practical_relevance": null,
      "recommended_actions": [],
      "risks_and_limits": [],
      "repeated_in_window": false,
      "repeated_days_ago": null
    },
    {
      "rank": 4,
      "title": "Zooming without Zooming: Region-to-Image Distillation for Fine-Grained Multimodal Perception",
      "paper_id": "2602.11858",
      "url": "https://huggingface.co/papers/2602.11858",
      "arxiv_url": "https://arxiv.org/abs/2602.11858",
      "upvotes": 50,
      "summary": "MLLMì˜ ë¯¸ì„¸í•œ ì¸ì‹ ëŠ¥ë ¥ í–¥ìƒì„ ìœ„í•´ ì¶”ë¡  ì‹œì ì— zoomingì„ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹ , region-to-image distillationì„ í†µí•´ í•™ìŠµ ì‹œì ì— zooming íš¨ê³¼ë¥¼ ë‚´ë„ë¡ í•˜ì—¬ inference latencyë¥¼ ì¤„ì´ê³  ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ë‹¤.",
      "key_points": [
        "Region-to-Image Distillationì„ í†µí•œ MLLMì˜ fine-grained perception ì„±ëŠ¥ í–¥ìƒ",
        "Zoomingì„ í•™ìŠµ ë‹¨ê³„ì— í†µí•©í•˜ì—¬ inference latency ê°ì†Œ",
        "Fine-grained perception í‰ê°€ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ ZoomBench ì œì‹œ"
      ],
      "tags": [
        "MLLM",
        "Distillation",
        "Fine-grained Perception",
        "VQA",
        "Zooming",
        "Agent",
        "Reasoning",
        "Multimodal",
        "Vision",
        "Benchmark",
        "Evaluation",
        "Inference"
      ],
      "confidence": "ìƒ",
      "adoption_complexity": "ì¤‘",
      "practical_relevance": "MLLM ê¸°ë°˜ ì„œë¹„ìŠ¤ë¥¼ ê°œë°œí•  ë•Œ, fine-grained perception ì„±ëŠ¥ì´ ì¤‘ìš”í•œ ê²½ìš° (ì˜ˆ: GUI ìë™í™”, ì˜ë£Œ ì˜ìƒ ë¶„ì„ ë“±) inference latency ì¦ê°€ ì—†ì´ ì„±ëŠ¥ í–¥ìƒì„ ê¸°ëŒ€í•  ìˆ˜ ìˆë‹¤.",
      "recommended_actions": [
        "ì œê³µëœ github repositoryë¥¼ í†µí•´ pre-trained ëª¨ë¸ ì‚¬ìš©í•´ë³´ê¸°",
        "ZoomBench ë°ì´í„°ì…‹ì„ ì´ìš©í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë° ê°œì„ ",
        "ìì²´ ë°ì´í„°ì…‹ì— Region-to-Image Distillation ì ìš©í•´ë³´ê¸°"
      ],
      "risks_and_limits": [
        "Distillation ê³¼ì •ì—ì„œ ì •ë³´ ì†ì‹¤ ê°€ëŠ¥ì„±",
        "ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ ZoomBenchì˜ ì¼ë°˜í™” ê°€ëŠ¥ì„±"
      ],
      "repeated_in_window": false,
      "repeated_days_ago": null
    },
    {
      "rank": 5,
      "title": "OneVision-Encoder: Codec-Aligned Sparsity as a Foundational Principle for Multimodal Intelligence",
      "paper_id": "2602.08683",
      "url": "https://huggingface.co/papers/2602.08683",
      "arxiv_url": "https://arxiv.org/abs/2602.08683",
      "upvotes": 38,
      "summary": "ë™ì˜ìƒ ì½”ë±ì˜ ì •ë³´ ì´ë¡ ì  ì›ë¦¬ë¥¼ í™œìš©í•˜ì—¬ ì‹œê°ì  ì •ë³´ë¥¼ ì••ì¶•í•˜ê³  LLMì— í†µí•©í•¨ìœ¼ë¡œì¨, ê¸°ì¡´ Vision ë°±ë³¸ ëª¨ë¸ ëŒ€ë¹„ ë” ì ì€ ì—°ì‚°ëŸ‰ê³¼ ë°ì´í„°ë¡œ ë” ë†’ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ëŠ” ìƒˆë¡œìš´ ì‹œê° ì¸ì½”ë” ì•„í‚¤í…ì²˜ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.",
      "key_points": [
        "ì½”ë± ê¸°ë°˜ì˜ í¬ì†Œì„± ì—°ì‚°ìœ¼ë¡œ íš¨ìœ¨ì ì¸ ì‹œê° ì •ë³´ ì²˜ë¦¬",
        "3D RoPEë¥¼ í™œìš©í•œ ê³µê°„-ì‹œê°„ ì •ë³´ í†µí•©",
        "ëŒ€ê·œëª¨ í´ëŸ¬ìŠ¤í„° íŒë³„ í•™ìŠµì„ í†µí•œ ê°ì²´ ì˜ì†ì„± ë° ì›€ì§ì„ ì—­í•™ í•™ìŠµ"
      ],
      "tags": [
        "Vision",
        "LLM",
        "Compression",
        "Codec",
        "Sparsity",
        "RAG",
        "Reasoning",
        "Multimodal",
        "Video",
        "Benchmark",
        "Optimization"
      ],
      "confidence": "ì¤‘",
      "adoption_complexity": "ì¤‘",
      "practical_relevance": "ë¹„ë””ì˜¤/ì´ë¯¸ì§€ ì²˜ë¦¬ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´, ì½”ë±ì˜ ì •ë³´ ì••ì¶• ì›ë¦¬ë¥¼ ëª¨ë¸ ì„¤ê³„ì— ë°˜ì˜í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì„ ì œê³µí•©ë‹ˆë‹¤. LLM ê¸°ë°˜ì˜ ë©€í‹°ëª¨ë‹¬ ì‹œìŠ¤í…œì—ì„œ ë¹„ì „ ëª¨ë¸ì˜ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "recommended_actions": [
        "ìì²´ ë°ì´í„°ì…‹ì— OV-Encoder ì ìš©í•˜ì—¬ ì„±ëŠ¥ ë° íš¨ìœ¨ì„± ë¹„êµ",
        "ê¸°ì¡´ ë¹„ì „ ëª¨ë¸ì— ì½”ë± ê¸°ë°˜ í¬ì†Œì„± ì—°ì‚° ë„ì… ì‹œë„",
        "3D RoPEë¥¼ í™œìš©í•˜ì—¬ ê³µê°„-ì‹œê°„ ì •ë³´ ì²˜ë¦¬ ì„±ëŠ¥ í–¥ìƒ ì‹¤í—˜"
      ],
      "risks_and_limits": [
        "íŠ¹ì • ìœ í˜•ì˜ ë¹„ë””ì˜¤ ë°ì´í„°ì— í¸í–¥ë  ê°€ëŠ¥ì„±",
        "ì½”ë± íŒ¨ì¹˜í™” ê³¼ì •ì—ì„œ ì¤‘ìš”í•œ ì •ë³´ ì†ì‹¤ ê°€ëŠ¥ì„±"
      ],
      "repeated_in_window": false,
      "repeated_days_ago": null
    }
  ]
}