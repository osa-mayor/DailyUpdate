# 2026-01-23 Daily Papers (Top 5)

## 1. [EvoCUA: Evolving Computer Use Agents via Learning from Scalable Synthetic Experience](https://huggingface.co/papers/2601.15876)
**Upvotes**: 75

![Thumbnail](images/EvoCUA_Evolving_Computer_Use_Agents_via_Learning_from_Scalable_Synthetic_Experience_img.jpg)

### 📌 요약
정적인 데이터 모방의 한계를 극복하고, 자가 생성 및 자가 교정의 진화적 학습 순환을 통해 컴퓨터 사용 에이전트(CUA)의 성능을 개방형 모델 최고 수준으로 끌어올린 혁신적인 방법론입니다.

### � 핵심 포인트
- 데이터 생성과 정책 최적화를 결합한 자가 지속적인 진화 학습 순환(Evolutionary Cycle)이 핵심 혁신입니다.
- OSWorld 벤치마크에서 56.7% 성공률을 달성하며, 기존 개방형 및 주요 비공개 모델 대비 최고 성능(SOTA)을 기록했습니다.
- 복잡한 컴퓨터 자동화(Native Agent) 연구자 및 개발자를 위한 논문이며, 다양한 기반 모델에서 확장 가능한 에이전트 능력 향상 경로를 제시합니다.

### 📝 초록 (번역)
네이티브 컴퓨터 사용 에이전트(CUA)는 멀티모달 AI의 중요한 발전 방향이지만, 기존 모델들이 정적인 데이터의 수동적인 모방에만 의존하면서 복잡하고 장기적인 컴퓨터 작업의 인과 관계를 학습하는 데 한계가 있었습니다. 

EvoCUA는 이 문제를 해결하기 위해 데이터 생성과 에이전트 정책 최적화를 통합한 '자가 지속적인 진화 학습 순환'을 도입했습니다. EvoCUA는 검증 가능한 합성 엔진을 통해 스스로 다양한 작업과 평가 기준을 만들고, 수만 개의 샌드박스 환경에서 대규모 경험을 비동기적으로 획득합니다. 이 과정에서 에이전트의 성공과 실패 경계를 분석하여 성공적인 루틴은 강화하고 실패 사례는 정교한 자체 교정 데이터로 변환하는 효율적인 학습 전략을 사용합니다.

실험 결과, EvoCUA는 OSWorld 벤치마크에서 56.7%의 성공률을 기록하며 이전 최고의 개방형 모델(OpenCUA-72B, 45.0%)은 물론, 주요 비공개 모델(UI-TARS-2, 53.1%)까지 뛰어넘는 새로운 개방형 최고 성능을 확립했습니다. 이 진화적 접근 방식은 모델 규모와 관계없이 일관된 성능 향상을 제공하며, 네이티브 에이전트 역량을 발전시키는 견고하고 확장 가능한 경로를 제시합니다.


---

## 2. [HERMES: KV Cache as Hierarchical Memory for Efficient Streaming Video Understanding](https://huggingface.co/papers/2601.14724)
**Upvotes**: 66

![Thumbnail](images/HERMES_KV_Cache_as_Hierarchical_Memory_for_Efficient_Streaming_Video_Understanding_img.jpg)

### 📌 요약
HERMES는 KV 캐시를 계층적 메모리로 혁신적으로 재해석하여, 실시간 스트리밍 비디오 이해에서 기존 대비 10배 빠른 응답 속도와 메모리 효율성을 동시에 달성한 획기적인 모델입니다.

### � 핵심 포인트
- 핵심 혁신: KV 캐시를 계층적 메모리 구조로 재해석하여, 추가 학습 없이(Training-Free) 적은 자원으로도 효율적인 스트리밍 이해가 가능합니다.
- 성능/결과: 기존 SOTA 대비 첫 토큰 출력 시간(TTFT)을 10배 단축하고, 비디오 토큰을 68% 줄였음에도 스트리밍 데이터셋에서 최대 11.4%의 정확도 향상을 달성했습니다.
- 대상/응용: GPU 메모리 등 자원 제약이 있는 환경에서 실시간 응답이 필수적인 연속적인 비디오 스트림 상호작용 및 이해 연구 분야.

### 📝 초록 (번역)
최근 MLLM(멀티모달 대규모 언어 모델) 덕분에 녹화된(오프라인) 비디오를 이해하는 능력은 크게 발전했지만, 이 기술을 실시간 스트리밍 비디오에 적용하는 것은 여전히 어렵습니다. 기존 모델들은 안정적인 성능을 유지하면서 동시에 빠른 응답 속도와 낮은 GPU 메모리 사용량을 확보하는 데 어려움을 겪었습니다. 이 문제를 해결하기 위해 저희는 HERMES라는 새로운 무학습(Training-Free) 아키텍처를 제안합니다. HERMES는 KV 캐시를 비디오 정보를 여러 세밀한 단위로 압축하는 '계층적 메모리'로 재개념화합니다. 이를 통해 추론 시 효율적이고 압축된 KV 캐시를 재사용하여 자원 제약 하에서도 스트리밍 이해가 가능해지며, 특히 사용자 질의가 들어왔을 때 추가적인 연산이 전혀 필요 없다는 것이 핵심입니다. 그 결과, HERMES는 기존 최신 기술(SOTA) 대비 TTFT(첫 토큰 출력 시간)를 10배 빠르게 단축시켰습니다. 심지어 기존 방식보다 비디오 토큰을 68%나 줄였음에도 불구하고 모든 벤치마크에서 같거나 더 나은 정확도를 보였으며, 스트리밍 데이터셋에서는 최대 11.4%의 성능 향상을 기록했습니다.


---

## 3. [LLM-in-Sandbox Elicits General Agentic Intelligence](https://huggingface.co/papers/2601.16206)
**Upvotes**: 63

![Thumbnail](images/LLM-in-Sandbox_Elicits_General_Agentic_Intelligence_img.jpg)

### 📌 요약
코드 샌드박스 환경을 제공하여 LLM이 추가 학습 없이도 외부 자원 활용, 장문맥 처리 등 범용적인 에이전트 지능을 다양한 비(非)코드 영역에서 발현하도록 유도하고 그 성능을 입증했습니다.

### � 핵심 포인트
- 핵심 혁신: LLM이 가상 컴퓨터(코드 샌드박스) 환경에서 스스로 탐색하고 도구를 활용하여 비(非)코드 영역까지 범용적인 에이전트 지능을 발현할 수 있도록 만든 프레임워크.
- 성능 및 결과: 추가 학습 없이도 샌드박스 사용 능력을 다양한 도메인에서 일반화하고, 특화된 RL(LLM-in-Sandbox-RL)을 통해 수학, 과학, 의학, 장문맥 처리 등 다영역에서 강력하고 일반화된 에이전트 성능을 달성함.
- 대상 및 응용: LLM의 범용성과 자율성을 높여 실제 환경에서 복잡한 문제를 해결하려는 AI 연구자 및 개발자. 효율성 분석을 제공하며 Python 패키지로 공개되어 즉시 배포 및 활용 가능.

### 📝 초록 (번역)
기존 LLM은 추론 능력이 뛰어나지만, 외부 정보 습득이나 복잡한 환경과의 상호작용 등 에이전트 지능(Agentic Intelligence)이 부족하여 범용적인 문제 해결에 한계가 있었습니다. 이 문제를 해결하기 위해, 우리는 LLM에 가상 컴퓨터 역할을 하는 코드 샌드박스 환경을 제공하는 'LLM-in-Sandbox' 프레임워크를 제안합니다. 놀랍게도, 강력한 LLM은 별도의 훈련 없이도 샌드박스를 활용하여 새로운 지식을 습득하거나 파일 시스템으로 긴 문맥을 처리하는 등 비(非)코드 영역에서도 에이전트 기능을 자발적으로 발휘했습니다. 나아가, 비(非)에이전트 데이터만을 사용하여 모델을 샌드박스 탐색에 특화시키는 'LLM-in-Sandbox-RL' 기법을 통해 이러한 능력을 더욱 강화했습니다. 결과적으로, LLM-in-Sandbox는 수학, 물리학, 화학, 생명 의학, 장문맥 이해 등 광범위한 영역에서 강력하고 일반화된 에이전트 성능을 입증했으며, 실제 배포를 용이하게 하기 위해 Python 패키지로 공개되었습니다.


---

## 4. [The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models](https://huggingface.co/papers/2601.15165)
**Upvotes**: 59

![Thumbnail](images/The_Flexibility_Trap_Why_Arbitrary_Order_Limits_Reasoning_Potential_in_Diffusion_Language_Models_img.jpg)

### 📌 요약
확산 LLM의 임의적 순서 생성의 함정을 밝혀내고, 복잡한 유연성을 의도적으로 포기하는 단순한 GRPO 기반 접근법인 JustGRPO를 통해 복잡한 추론 문제에서 최고 성능(GSM8K 89.1%)을 달성했습니다.

### � 핵심 포인트
- 핵심 기여: 확산 LLM에서 임의적 생성 순서가 추론 능력 발현을 방해하는 '유연성 함정(Flexibility Trap)'을 발견하고, 이를 해결하기 위해 단순화된 순서를 사용하는 JustGRPO 방법을 제안함.
- 성능/결과: 수학 추론 벤치마크인 GSM8K에서 89.1%의 정확도를 달성하며, 복잡한 추론 작업에서 최고 수준의 성능을 입증함.
- 대상/응용: 확산 언어 모델(dLLM)의 구조적 한계를 극복하고 추론 능력 향상 및 효율적인 RL 기반 학습 기법을 모색하는 개발자 및 연구자.

### 📝 초록 (번역)
확산 대규모 언어 모델(dLLMs)은 기존 LLM과 달리 토큰을 좌우로 고정하지 않고 임의의 순서로 생성할 수 있습니다. 이러한 유연성은 수학이나 코딩 같은 복잡한 추론 작업에서 기존 방식보다 훨씬 뛰어난 잠재력을 가질 것으로 기대되어, 많은 연구에서 강화 학습(RL)을 동원하여 이 임의적 순서의 추론 능력을 끌어내려 했습니다.

**[문제]** 본 연구는 역설적인 현실을 발견했습니다. 현재의 임의적 순서 생성은 추론 경계를 확장하기는커녕 오히려 축소시킨다는 것입니다. dLLM은 이 유연성을 악용하여 탐색에 필수적인 '불확실성이 높은 토큰'을 회피하는 경향이 있으며, 그 결과 해답 공간이 너무 일찍 붕괴되는 현상, 즉 ‘유연성 함정(Flexibility Trap)’에 빠집니다.

**[해결책]** 이러한 발견은 복잡한 조합적 궤적과 난해한 우도(likelihood) 처리에 리소스를 투입하며 유연성을 유지하려는 기존 RL 접근법의 전제 자체를 흔듭니다. 따라서 연구팀은 임의적 순서를 의도적으로 포기하고, 표준적인 GRPO(Group Relative Policy Optimization)를 적용하는 미니멀리스트 접근법인 JustGRPO를 제안했습니다.

**[결과]** JustGRPO는 단순하지만 놀라울 정도로 효과적이며, GSM8K 수학 벤치마크에서 89.1%의 높은 정확도를 달성했습니다. 이는 dLLM의 핵심 장점인 병렬 디코딩 능력을 완벽하게 유지하면서 추론 능력을 성공적으로 끌어낸 결과입니다.


---

## 5. [BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries](https://huggingface.co/papers/2601.15197)
**Upvotes**: 53

![Thumbnail](images/BayesianVLA_Bayesian_Decomposition_of_Vision_Language_Action_Models_via_Latent_Action_Queries_img.jpg)

### 📌 요약
기존 VLA 모델의 언어 지시 무시 문제를 해결하기 위해 베이지안 분해와 잠재 액션 쿼리(Latent Action Queries)를 도입하여, OOD 환경에서의 일반화 성능을 획기적으로 개선한 새로운 VLA 프레임워크를 제시합니다.

### � 핵심 포인트
- 베이지안 분해 기반의 언어 강제 준수 프레임워크: 잠재 액션 쿼리를 사용하여 시각 우선 예측(Prior)과 언어 조건부 예측(Posterior)을 분리 추정하고, 조건부 PMI 최적화를 통해 '정보 붕괴' 현상을 방지합니다.
- 성능 및 결과: 새로운 데이터 없이도 OOD(Out-of-Distribution) 환경에서 강력한 일반화 성능을 달성했으며, 특히 도전적인 SimplerEnv 벤치마크에서 11.3%의 성능 향상을 기록했습니다.
- 활용 대상: VLA 모델의 일반화 능력과 신뢰성 있는 언어 이해 능력을 필요로 하는 로봇 공학 연구자 및 복잡한 멀티태스크 환경의 로봇 제어 정책 개발자.

### 📝 초록 (번역)
시각-언어-행동(VLA) 모델은 로봇 조작 분야에서 큰 기대를 받고 있지만, 현재의 훈련 방식에는 치명적인 결함이 있습니다. 목표 지향적 데이터 수집 과정에서 언어 지시가 시각적 관찰만으로도 너무 쉽게 예측되는 데이터셋 편향이 발생하며, 이는 모델이 언어 제약을 무시하고 시각 정보에만 의존하는 '정보 붕괴(Information Collapse)' 현상을 초래합니다. 그 결과, 모델은 학습 데이터와 다른(OOD) 환경에서 형편없이 실패하게 됩니다. 

이를 해결하기 위해 본 연구는 'BayesianVLA'라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 베이지안 분해 원리를 활용하여 언어 준수(Instruction Following)를 강제합니다. 학습 가능한 잠재 액션 쿼리(Latent Action Queries)를 도입하고, 시각 정보만 사용하는 사전 예측(Vision-only prior)과 언어 조건부 사후 예측(Language-conditioned posterior)을 동시에 추정하는 이중 분기 아키텍처를 구축합니다. 우리는 행동과 지시 사이의 조건부 상호 정보(PMI)를 최대화하도록 정책을 최적화합니다. 이 목적 함수는 시각 정보만을 이용하는 '손쉬운 경로(Vision Shortcut)'를 효과적으로 차단하고, 언어 명령을 명확하게 설명하는 행동에만 보상을 부여합니다. 

BayesianVLA는 새로운 데이터를 요구하지 않으면서도 일반화 성능을 크게 개선했습니다. SimplerEnv 및 RoboCasa에 대한 광범위한 실험에서 도전적인 OOD SimplerEnv 벤치마크에서 11.3%의 성능 향상을 포함한 상당한 이득을 입증하며, 언어를 행동에 견고하게 접지시키는(Grounding) 능력을 검증했습니다.


---

