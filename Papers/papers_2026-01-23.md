# 2026-01-23 Daily Papers (Top 5)

## 1. [EvoCUA: Evolving Computer Use Agents via Learning from Scalable Synthetic Experience](https://huggingface.co/papers/2601.15876)
**Upvotes**: 69

![Thumbnail](images/EvoCUA_Evolving_Computer_Use_Agents_via_Learning_from_Scalable_Synthetic_Experience_img.jpg)

### 📌 요약
정적인 모방 학습의 한계를 돌파하고 자체적으로 진화하는 학습 사이클을 도입하여, OSWorld 벤치마크에서 기존 최고 모델들을 제치고 개방형 소스 컴퓨터 사용 에이전트(CUA)의 새로운 기준을 세웠습니다.

### � 핵심 포인트
- 데이터 생성과 정책 최적화를 통합하고, 실패 사례를 학습으로 전환하는 '자기 진화적 학습 사이클' 도입 (핵심 혁신)
- OSWorld 벤치마크에서 56.7% 성공률을 달성, 기존 오픈소스 및 주요 폐쇄형 모델을 능가하는 새로운 오픈소스 최고 성능(SOTA) 기록
- 대규모 합성 데이터 기반의 범용 컴퓨터 사용 에이전트(CUA) 개발을 목표로 하는 AI 연구자 및 개발자

### 📝 초록 (번역)
네이티브 컴퓨터 사용 에이전트(CUA)는 멀티모달 AI의 핵심이지만, 기존 모델들은 정적인 데이터에만 의존하여 복잡하고 장기적인 컴퓨터 작업의 인과 관계를 파악하는 데 한계가 있었습니다. 이러한 데이터 규모의 병목 현상을 해결하기 위해, 본 연구는 데이터 생성과 정책 최적화를 통합하는 자기 진화적인 사이클을 갖춘 EvoCUA를 제안합니다. EvoCUA는 검증 가능한 합성 엔진을 통해 실행 가능한 검증기를 갖춘 다양한 가상 작업을 스스로 생성하고, 수만 개의 샌드박스 환경을 활용하는 확장 가능한 인프라를 구축하여 대규모 경험을 효율적으로 축적합니다. 특히, 성공 경험은 강화하고 실패 경험은 오류 분석과 자기 교정을 통해 풍부한 학습 데이터로 전환하는 '반복적 진화 학습 전략'을 사용합니다. 실험 결과, EvoCUA는 OSWorld 벤치마크에서 56.7%의 성공률을 기록하며 기존의 오픈소스 최고 모델(OpenCUA-72B, 45.0%)은 물론, 폐쇄형 최고 모델(UI-TARS-2, 53.1%)까지 뛰어넘는 새로운 오픈소스 SOTA를 달성했습니다. 이는 EvoCUA의 진화적 학습 패러다임이 에이전트 성능을 향상시키는 강력하고 확장 가능한 경로임을 입증합니다.


---

## 2. [HERMES: KV Cache as Hierarchical Memory for Efficient Streaming Video Understanding](https://huggingface.co/papers/2601.14724)
**Upvotes**: 59

![Thumbnail](images/HERMES_KV_Cache_as_Hierarchical_Memory_for_Efficient_Streaming_Video_Understanding_img.jpg)

### 📌 요약
HERMES는 KV 캐시를 계층적 메모리로 활용하여 정확도를 유지하면서도 스트리밍 비디오 분석 속도를 기존 대비 10배 향상시키고 GPU 메모리 효율성을 극대화한 획기적인 아키텍처입니다.

### � 핵심 포인트
- 핵심 기여: KV 캐시를 멀티 그레인(multi-granularity) 정보를 포괄하는 계층적 메모리로 재개념화한 무학습(training-free) 아키텍처.
- 성능 및 결과: 기존 SOTA 대비 TTFT(첫 토큰 생성 시간) 10배 가속, 토큰 68% 절감에도 정확도 유지 및 스트리밍 데이터셋에서 최대 11.4% 정확도 향상.
- 응용 분야 및 대상: 저지연(low-latency)이 필수적인 자원 제약 환경에서 실시간 스트리밍 비디오 분석 및 이해 기술 개발이 필요한 연구자 및 개발자.

### 📝 초록 (번역)
최근 MLLM(멀티모달 대규모 언어 모델)의 발전으로 오프라인 비디오 이해 능력은 크게 향상되었습니다. 하지만 이 기술을 실시간 스트리밍 비디오에 적용하는 것은 어려운 도전 과제로 남아 있습니다. 기존 모델들은 안정적인 분석 성능, 실시간 응답 속도, 낮은 GPU 메모리 오버헤드를 동시에 확보하는 데 어려움을 겪습니다. 이러한 문제를 해결하기 위해, 우리는 'HERMES'라는 새로운 무학습(training-free) 아키텍처를 제안합니다. HERMES는 KV 캐시를 다양한 세부 정보를 포괄하는 '계층적 메모리 프레임워크'로 개념화합니다. 추론 과정에서 HERMES는 이 압축된(compact) KV 캐시를 효율적으로 재활용하여 자원 제약 환경에서도 스트리밍 이해 능력을 높입니다. 특히, 사용자 질의가 들어와도 추가적인 연산(auxiliary computations)이 필요 없기 때문에 실시간 응답이 보장됩니다. 결과적으로 HERMES는 기존 최고 성능 모델 대비 TTFT(첫 토큰 생성 시간)를 10배 빠르게 달성했으며, 비디오 토큰을 최대 68%까지 줄였음에도 동등하거나 더 뛰어난 정확도를 보였고, 스트리밍 데이터셋에서는 최대 11.4%의 성능 향상을 기록했습니다.


---

## 3. [The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models](https://huggingface.co/papers/2601.15165)
**Upvotes**: 57

![Thumbnail](images/The_Flexibility_Trap_Why_Arbitrary_Order_Limits_Reasoning_Potential_in_Diffusion_Language_Models_img.jpg)

### 📌 요약
확산 언어 모델(dLLMs)에서 임의적인 토큰 생성 순서가 오히려 추론 능력을 제한한다는 통념을 깨고, 단순화된 정책 최적화(JustGRPO)를 통해 높은 정확도(GSM8K 89.1%)를 달성하면서도 병렬 디코딩 능력을 유지하는 효율적인 추론 방식을 제안했습니다.

### � 핵심 포인트
- 임의 순서 생성의 함정(Flexibility Trap)을 밝혀내고, 순서 유연성을 포기한 단순화된 GRPO 기반 추론 방식인 JustGRPO를 제안함.
- GSM8K 벤치마크에서 89.1%의 높은 정확도를 달성하며, 효율성과 병렬 디코딩 능력을 모두 유지함.
- dLLM, 강화 학습 기반 최적화 연구자 및 수학적 추론, 코딩 등 복잡한 태스크의 추론 능력 향상을 목표로 하는 개발자.

### 📝 초록 (번역)
확산 언어 모델(dLLMs)은 기존 LLM의 경직된 순서(왼쪽-오른쪽)를 벗어나 토큰을 임의의 순서대로 생성하는 유연성을 제공합니다. 많은 연구자들은 이러한 유연성이 수학이나 코딩 같은 복잡한 추론 작업에서 훨씬 넓은 해결 공간을 열어줄 것이라 기대하며 강화 학습(RL)을 활용해 그 잠재력을 끌어내려 했습니다. 

하지만 본 연구는 임의적 순서 생성(The Flexibility Trap)이 오히려 dLLM의 추론 범위를 좁힌다는 역직관적인 현실을 밝혀냈습니다. 모델이 이 유연성을 악용하여 탐색에 필수적인 '불확실성이 높은 토큰' 생성을 회피하고, 이로 인해 해결 공간이 너무 일찍 축소되는 현상이 발생합니다. 이는 이 유연성을 보존하기 위해 복잡한 RL 기법을 동원했던 기존 접근 방식들의 전제를 근본적으로 뒤집습니다.

우리의 해결책은 단순합니다. 임의적 순서 생성을 의도적으로 포기하고, 대신 표준적인 GRPO(Group Relative Policy Optimization)를 적용할 때 훨씬 효과적인 추론 능력이 발현됨을 증명했습니다. 우리의 접근법인 'JustGRPO'는 최소한의 방식이지만 놀라운 효과를 보이며 (예: GSM8K 벤치마크에서 89.1% 정확도 달성), dLLM의 핵심 장점인 병렬 디코딩 능력은 그대로 유지합니다.


---

## 4. [LLM-in-Sandbox Elicits General Agentic Intelligence](https://huggingface.co/papers/2601.16206)
**Upvotes**: 55

![Thumbnail](images/LLM-in-Sandbox_Elicits_General_Agentic_Intelligence_img.jpg)

### 📌 요약
코드 샌드박스를 활용하여 비(非)코드 영역에서도 범용적인 에이전트 지능을 자동으로 이끌어내고, LLM의 복잡한 문제 해결 능력을 획기적으로 향상시킨 혁신적인 프레임워크를 제안했습니다.

### � 핵심 포인트
- 코드 샌드박스를 활용하여 LLM의 범용 에이전트 지능을 훈련 없이도 자발적으로 이끌어내는 방법론 제시. (Key Contribution)
- 수학, 과학, 장문 이해 등 광범위한 비(非)코드 영역에 걸쳐 강력한 일반화 능력과 문제 해결 능력 입증. (Performance/Results)
- 실제 시스템 통합을 위해 Python 패키지로 오픈 소스화되어, 에이전트 LLM 연구자 및 개발자들의 실무 적용 가능. (Target/Application)

### 📝 초록 (번역)
기존 LLM은 자체 지식에 국한되어 복잡하거나 최신 지식이 필요한 비(非)코드 문제(수학, 과학, 장문 이해 등)를 해결하는 데 한계가 있었습니다. 이 문제를 해결하기 위해, 연구진은 LLM에게 'LLM-in-Sandbox'라는 가상의 컴퓨터 환경(코드 샌드박스)을 제공하여, LLM이 외부 자원 접근, 파일 시스템 활용, 스크립트 실행 등을 스스로 수행하도록 만들었습니다. 놀랍게도 별도 훈련 없이도 강력한 LLM은 이 환경을 즉각 활용하여 복잡한 비코드 태스크를 해결하는 일반화 능력을 보였습니다. 또한, 비(非)에이전트 데이터를 사용한 'LLM-in-Sandbox-RL' 후속 훈련을 통해 이러한 에이전트 기능을 더욱 강화할 수 있음을 입증했습니다. 그 결과, LLM-in-Sandbox는 수학, 물리, 화학, 생의학, 장문 처리 등 광범위한 영역에서 강력하고 일반화된 문제 해결 능력을 달성했습니다. 이 시스템은 파이썬 패키지로 공개되어 실제 환경에 쉽게 배포 가능합니다.


---

## 5. [BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries](https://huggingface.co/papers/2601.15197)
**Upvotes**: 51

![Thumbnail](images/BayesianVLA_Bayesian_Decomposition_of_Vision_Language_Action_Models_via_Latent_Action_Queries_img.jpg)

### 📌 요약
베이지안 분해와 조건부 상호 정보(PMI)를 활용하여 기존 VLA 모델의 '정보 붕괴' 현상을 해결하고, 데이터 추가 없이도 OOD 환경에서 로봇의 언어 지시 이행 능력을 획기적으로 향상시켰습니다.

### � 핵심 포인트
- 핵심 기여: VLA 모델의 훈련 과정에서 발생하는 '정보 붕괴' 문제를 해결하기 위해 베이지안 분해와 조건부 상호 정보(PMI) 최대화 목표를 도입하여, 모델이 언어 지시를 필수적으로 따르도록 강제하는 아키텍처를 설계했습니다.
- 성능/결과: 새로운 데이터 수집 없이 OOD 환경에 대한 일반화 성능을 대폭 개선했으며, 특히 난이도가 높은 OOD SimplerEnv 벤치마크에서 11.3%의 유의미한 성능 향상을 기록했습니다.
- 타겟/응용: 로봇 조작 분야의 VLA 모델 개발자 및 연구원. 언어 지시에 대한 일반화와 강건성(Robustness)이 필수적인 복잡한 멀티태스크 및 현실 세계의 로봇 응용 시나리오에 즉시 적용하여 정책 신뢰도를 높일 수 있습니다.

### 📝 초록 (번역)
로봇 조작 분야에서 Vision-Language-Action(VLA) 모델은 큰 기대를 받고 있지만, 현재의 훈련 방식에는 치명적인 결함이 있습니다. 목표 지향적인 데이터 수집으로 인해 시각 정보만으로도 언어 지시를 쉽게 예측할 수 있는 '정보 붕괴(Information Collapse)' 현상이 발생합니다. 이로 인해 모델은 언어를 무시하는 '시각 전용 정책'으로 퇴화하며, 낯선 환경(OOD)에서 실패하게 됩니다. 

이러한 문제를 해결하기 위해 우리는 BayesianVLA라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 베이지안 분해를 기반으로 하며, '잠재 행동 쿼리(Latent Action Queries)'를 도입한 이중 분기 아키텍처를 구축합니다. 이 아키텍처는 시각 전용 사전 확률과 언어 조건부 사후 확률을 동시에 추정합니다. 핵심은 행동과 지시 사이의 조건부 상호 정보(PMI)를 최대화하는 방향으로 정책을 최적화하는 것입니다. 이 과정을 통해 모델은 시각적인 지름길을 피하고, 언어 명령을 명시적으로 이해하고 설명하는 행동을 취하도록 강제됩니다. 

새로운 데이터를 필요로 하지 않음에도 불구하고, BayesianVLA는 SimplerEnv와 RoboCasa 벤치마크 전반에서 뛰어난 일반화 성능을 입증했으며, 특히 어려운 OOD SimplerEnv 벤치마크에서 11.3%의 성능 향상을 달성하며 언어 기반 로봇 조작의 강건성을 검증했습니다.


---

