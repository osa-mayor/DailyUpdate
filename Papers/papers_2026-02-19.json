{
  "source": "huggingface_papers",
  "date": "2026-02-19",
  "generated_at": "2026-02-20T04:40:05.721305+09:00",
  "count": 5,
  "chat_message": "🔥 오늘의 논문\n\n📍 1. SLA2: Sparse-Linear Attention with Learnable Routing and QAT\n📝 요약: 비디오 생성 모델에서 Sparse-Linear Attention의 단점을 개선하여 연산 속도를 대폭 향상시키고 양자화 오류를 줄이는 새로운 Sparse-Linear Attention 구조(SLA2)를 제안합니다.\n🔗 Hugging Face: https://huggingface.co/papers/2602.12675\n📄 arXiv: https://arxiv.org/abs/2602.12675\n\n📍 2. Learning Humanoid End-Effector Control for Open-Vocabulary Visual Loco-Manipulation\n📝 요약: 대규모 시뮬레이션 학습과 비전 모델을 결합하여 휴머노이드 로봇의 객체 조작 능력을 크게 향상시키는 새로운 접근법인 HERO를 제시, 실제 환경에서의 활용 가능성을 높임.\n🔗 Hugging Face: https://huggingface.co/papers/2602.16705\n📄 arXiv: https://arxiv.org/abs/2602.16705\n\n📍 3. RynnBrain: Open Embodied Foundation Models\n📝 요약: 실제 환경에서 작동하는 에이전트 개발을 위한 강력한 기반 모델 RynnBrain 공개: 다양한 embodied task에서 기존 모델을 크게 능가하며, 특히 물리적 추론 및 계획 능력 향상에 기여.\n🔗 Hugging Face: https://huggingface.co/papers/2602.14979\n📄 arXiv: https://arxiv.org/abs/2602.14979\n\n출처: Hugging Face Papers\nhttps://huggingface.co/papers\n\n👉 전체 리포트\nhttps://github.com/osa-mayor/DailyUpdate/blob/main/Papers/papers_2026-02-19.md",
  "items": [
    {
      "rank": 1,
      "title": "SLA2: Sparse-Linear Attention with Learnable Routing and QAT",
      "paper_id": "2602.12675",
      "url": "https://huggingface.co/papers/2602.12675",
      "arxiv_url": "https://arxiv.org/abs/2602.12675",
      "upvotes": 39,
      "summary": "비디오 생성 모델에서 Sparse-Linear Attention의 단점을 개선하여 연산 속도를 대폭 향상시키고 양자화 오류를 줄이는 새로운 Sparse-Linear Attention 구조(SLA2)를 제안합니다.",
      "korean_abstract": "Sparse-Linear Attention(SLA)은 비디오 생성 모델에서 효율적인 연산을 위해 사용되지만, 휴리스틱한 분할 방식과 부정확한 분해 방식으로 인해 성능 저하가 발생할 수 있습니다. 본 논문에서는 이러한 문제점을 해결하기 위해, (I) 학습 가능한 라우터를 통해 각 연산에 적합한 attention 방식을 선택하고, (II) sparse 및 linear attention 가지를 결합하는 학습 가능한 비율을 도입하여 더 정확한 sparse-linear attention 구조를 제안합니다. 또한 (III) 양자화 인지 fine-tuning을 통해 낮은 비트 attention을 도입하여 양자화 오류를 줄였습니다. 실험 결과, SLA2는 비디오 diffusion 모델에서 97%의 attention sparsity를 달성하고, 18.6배의 attention 속도 향상을 보이면서도 생성 품질을 유지했습니다.",
      "key_points": [
        "학습 가능한 라우터를 사용하여 sparse/linear attention을 동적으로 선택",
        "sparse 및 linear attention의 결합 비율을 학습 가능하게 만들어 정확도 향상",
        "양자화 인지 fine-tuning을 통해 낮은 비트 attention을 도입하여 양자화 오류 감소"
      ],
      "tags": [
        "Attention",
        "Sparse Attention",
        "Quantization",
        "Video Generation",
        "Diffusion Model",
        "Video",
        "Optimization"
      ],
      "confidence": "상",
      "adoption_complexity": "중",
      "practical_relevance": "기존 SLA의 한계를 극복하고 연산 효율성을 높이는 동시에 모델 성능을 유지하므로, 비디오 생성 모델 개발 시 리소스 제약 하에서 더 높은 품질의 결과물을 얻는 데 도움이 될 수 있습니다. 특히 모델 경량화 및 속도 향상이 중요한 분야에 적용 가능합니다.",
      "recommended_actions": [
        "SLA2를 기존 비디오 생성 모델에 적용하여 성능 및 속도 향상 비교",
        "SLA2의 학습 가능한 라우터 및 결합 비율 학습 과정 분석 및 시각화",
        "다양한 양자화 기법을 SLA2에 적용하여 성능 변화 관찰"
      ],
      "risks_and_limits": [
        "SLA2의 학습 가능한 파라미터 추가로 인한 메모리 사용량 증가 가능성",
        "특정 비디오 데이터셋에 과적합될 가능성"
      ],
      "repeated_in_window": false,
      "repeated_days_ago": null,
      "image_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.12675.png",
      "local_image_path": "images/SLA2_Sparse-Linear_Attention_with_Learnable_Routing_and_QAT_img.jpg",
      "local_figures": []
    },
    {
      "rank": 2,
      "title": "Learning Humanoid End-Effector Control for Open-Vocabulary Visual Loco-Manipulation",
      "paper_id": "2602.16705",
      "url": "https://huggingface.co/papers/2602.16705",
      "arxiv_url": "https://arxiv.org/abs/2602.16705",
      "upvotes": 25,
      "summary": "대규모 시뮬레이션 학습과 비전 모델을 결합하여 휴머노이드 로봇의 객체 조작 능력을 크게 향상시키는 새로운 접근법인 HERO를 제시, 실제 환경에서의 활용 가능성을 높임.",
      "korean_abstract": "휴머노이드 로봇을 이용한 시각적 조작은 정확한 엔드 이펙터 제어와 장면 이해가 필수적이지만, 기존의 모방 학습 방식은 데이터 부족으로 일반화에 어려움을 겪습니다. 본 논문에서는 대규모 비전 모델의 일반화 능력과 시뮬레이션 학습의 제어 성능을 결합한 HERO라는 새로운 패러다임을 제시합니다. 핵심은 잔차 인식 엔드 이펙터 추적 정책으로, 역기구학, 신경 순방향 모델, 목표 조정, 재계획 등을 활용하여 엔드 이펙터 추적 오차를 3.2배 감소시켰습니다. 이를 통해 다양한 실제 환경에서 일상적인 물체를 조작할 수 있는 모듈형 시스템을 구축했으며, 시뮬레이션 및 실제 환경 테스트를 통해 HERO의 효과를 입증했습니다.",
      "key_points": [
        "잔차 인식 엔드 이펙터 추적 정책 (residual-aware EE tracking policy) 제안",
        "대규모 비전 모델과 시뮬레이션 학습을 결합한 새로운 휴머노이드 로봇 제어 패러다임 (HERO) 제시",
        "실제 환경에서 다양한 객체 조작 가능성을 입증"
      ],
      "tags": [
        "Robotics",
        "Locomotion",
        "Manipulation",
        "Vision",
        "Simulation"
      ],
      "confidence": "상",
      "adoption_complexity": "중",
      "practical_relevance": "실제 로봇을 활용한 서비스 개발 시, 시뮬레이션 환경에서 학습된 모델을 통해 초기 데이터 확보의 어려움을 극복하고 다양한 환경에 대한 일반화 성능을 높일 수 있습니다. 특히 비전 모델과의 결합을 통해 객체 인식 및 조작의 유연성을 확보할 수 있다는 점에서 실용적입니다.",
      "recommended_actions": [
        "제시된 엔드 이펙터 추적 정책의 각 모듈(역기구학, 순방향 모델 등)별 성능 분석 및 개선",
        "자체 로봇 플랫폼에 HERO 프레임워크 적용 가능성 검토",
        "다른 시각 모델(예: CLIP)을 사용하여 객체 인식 성능 비교"
      ],
      "risks_and_limits": [
        "시뮬레이션 환경과 실제 환경 간의 차이(sim-to-real gap)로 인한 성능 저하 가능성",
        "대규모 비전 모델의 연산 자원 요구량으로 인한 실시간 제어의 어려움"
      ],
      "repeated_in_window": false,
      "repeated_days_ago": null,
      "image_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.16705.png",
      "local_image_path": "images/Learning_Humanoid_End-Effector_Control_for_Open-Vocabulary_Visual_Loco-Manipulation_img.jpg",
      "local_figures": []
    },
    {
      "rank": 3,
      "title": "RynnBrain: Open Embodied Foundation Models",
      "paper_id": "2602.14979",
      "url": "https://huggingface.co/papers/2602.14979",
      "arxiv_url": "https://arxiv.org/abs/2602.14979",
      "upvotes": 24,
      "summary": "실제 환경에서 작동하는 에이전트 개발을 위한 강력한 기반 모델 RynnBrain 공개: 다양한 embodied task에서 기존 모델을 크게 능가하며, 특히 물리적 추론 및 계획 능력 향상에 기여.",
      "korean_abstract": "최근 멀티모달 기초 모델의 발전에도 불구하고, embodied intelligence 분야는 현실 세계의 시공간적 역학 관계 내에서 인지, 추론, 계획을 통합하는 통일된 기초 모델이 부족했습니다. 본 논문에서는 embodied intelligence를 위한 오픈 소스 시공간 기초 모델인 RynnBrain을 소개합니다. RynnBrain은 포괄적인 자기 중심적 이해, 다양한 시공간적 위치 파악, 물리적으로 근거한 추론, 물리 기반 계획이라는 네 가지 핵심 기능을 강화합니다. RynnBrain은 다양한 규모의 기초 모델(2B, 8B, 30B-A3B MoE)과 다운스트림 embodied task에 특화된 네 가지 사전 훈련된 변형 모델(RynnBrain-Nav, RynnBrain-Plan, RynnBrain-VLA, RynnBrain-CoP)로 구성됩니다. 20개의 embodied 벤치마크와 8개의 일반 비전 이해 벤치마크에 대한 광범위한 평가에서 RynnBrain은 기존 모델을 크게 능가하며, 물리적 추론 및 계획을 가능하게 하고, 다양한 task에 효율적으로 적용 가능한 강력한 사전 훈련 백본으로서의 잠재력을 입증합니다.",
      "key_points": [
        "embodied intelligence를 위한 오픈 소스 시공간 기초 모델 RynnBrain 제안",
        "다양한 embodied task에 특화된 여러 사전 훈련된 변형 모델 제공",
        "기존 모델 대비 성능 향상 및 물리적 추론/계획 능력 향상 입증"
      ],
      "tags": [
        "Agent",
        "Embodied AI",
        "Foundation Model",
        "Robotics",
        "Planning",
        "Reasoning",
        "Multimodal",
        "Vision",
        "Benchmark",
        "Evaluation"
      ],
      "confidence": "상",
      "adoption_complexity": "중",
      "practical_relevance": "RynnBrain은 로보틱스, 자율 주행, AR/VR 등 실제 환경과의 상호 작용이 중요한 애플리케이션 개발에 유용한 기반 모델을 제공하며, 특히 물리적 세계에 대한 이해 및 추론 능력이 필요한 task에서 활용도가 높습니다.",
      "recommended_actions": [
        "RynnBrain 모델을 다운로드하여 자체 embodied agent 개발에 적용해보기",
        "RynnBrain의 사전 훈련된 변형 모델을 특정 task에 맞게 fine-tuning 해보기",
        "RynnBrain의 물리적 추론 및 계획 능력을 활용하여 새로운 embodied task를 정의하고 해결해보기"
      ],
      "risks_and_limits": [
        "모델의 크기가 커서 상당한 컴퓨팅 자원이 필요할 수 있음",
        "특정 환경이나 task에 overfitting될 가능성이 존재함"
      ],
      "repeated_in_window": false,
      "repeated_days_ago": null,
      "image_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.14979.png",
      "local_image_path": "images/RynnBrain_Open_Embodied_Foundation_Models_img.jpg",
      "local_figures": []
    },
    {
      "rank": 4,
      "title": "CADEvolve: Creating Realistic CAD via Program Evolution",
      "paper_id": "2602.16317",
      "url": "https://huggingface.co/papers/2602.16317",
      "arxiv_url": "https://arxiv.org/abs/2602.16317",
      "upvotes": 16,
      "summary": "VLM을 활용해 CAD 모델링 자동화를 위한 데이터셋을 구축하고, 이를 파인튜닝하여 Image2CAD 성능을 SOTA로 끌어올린 연구.",
      "korean_abstract": "CAD는 엔지니어링 및 제조 분야에서 중요한 역할을 하지만, AI 기반 자동화는 데이터 부족으로 인해 어려움을 겪고 있습니다. 기존 데이터셋은 단순한 형태이며, 복잡한 연산, 다중 연산 조합, 설계 의도 등이 부족하여 VLM의 3D 이해 능력을 제한합니다. 본 연구에서는 VLM을 활용하여 간단한 기본 도형에서 시작해 점진적으로 복잡한 CAD 프로그램을 생성하는 CADEvolve 파이프라인과 데이터셋을 제안합니다. 이를 통해 8천 개의 복잡한 부품과 130만 개의 스크립트-지오메트리 쌍을 포함하는 대규모 데이터셋을 구축했으며, CADEvolve로 파인튜닝된 VLM은 Image2CAD 태스크에서 SOTA 성능을 달성했습니다.",
      "key_points": [
        "VLM 기반 CAD 프로그램 진화 파이프라인 (CADEvolve) 제시",
        "130만 개의 CAD 스크립트-지오메트리 쌍으로 구성된 대규모 데이터셋 구축",
        "CADEvolve로 파인튜닝된 VLM이 Image2CAD 태스크에서 SOTA 달성"
      ],
      "tags": [
        "CAD",
        "VLM",
        "Data Generation",
        "Automation",
        "Image2CAD",
        "Vision",
        "Benchmark"
      ],
      "confidence": "상",
      "adoption_complexity": "중",
      "practical_relevance": "CAD 모델링 자동화에 필요한 고품질 데이터셋을 확보하고, VLM을 활용하여 이미지로부터 CAD 모델을 생성하는 파이프라인을 구축하는 데 참고할 수 있습니다.",
      "recommended_actions": [
        "CADEvolve 데이터셋을 활용하여 기존 CAD 모델링 파이프라인의 성능 개선 시도",
        "연구에서 사용된 VLM 아키텍처와 학습 전략을 다른 CAD 관련 태스크에 적용",
        "생성된 CAD 모델의 품질과 다양성을 평가하고, 개선 방향 모색"
      ],
      "risks_and_limits": [
        "생성된 CAD 프로그램의 유효성 검증에 대한 추가적인 연구 필요",
        "VLM의 3D 이해 능력은 여전히 제한적일 수 있으며, 복잡한 형상 모델링에는 어려움이 있을 수 있음"
      ],
      "repeated_in_window": false,
      "repeated_days_ago": null,
      "image_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.16317.png",
      "local_image_path": "images/CADEvolve_Creating_Realistic_CAD_via_Program_Evolution_img.jpg",
      "local_figures": []
    },
    {
      "rank": 5,
      "title": "Empty Shelves or Lost Keys? Recall Is the Bottleneck for Parametric Factuality",
      "paper_id": "2602.14080",
      "url": "https://huggingface.co/papers/2602.14080",
      "arxiv_url": "https://arxiv.org/abs/2602.14080",
      "upvotes": 15,
      "summary": "LLM의 Factuality 평가는 지식 부족뿐 아니라 접근 실패도 고려해야 하며, 특히 최신 모델은 지식 습득보다는 이미 습득한 지식을 효과적으로 활용하는 것이 중요합니다.",
      "korean_abstract": "LLM의 Factuality 평가는 오류의 원인을 명확히 구분하지 못하는 문제가 있습니다. 본 논문에서는 지식이 없는 경우(empty shelves)와 지식은 있지만 접근하지 못하는 경우(lost keys)를 구분하는 새로운 행동 프레임워크를 제안합니다. 이를 위해 웹 검색 기반으로 LLM을 활용하여 자동 구축된 WikiProfile 벤치마크를 도입했습니다. 실험 결과, 최신 모델은 대부분의 사실을 인코딩하고 있지만, 인코딩된 정보를 제대로 회수(recall)하지 못하는 경우가 많았습니다. 특히 꼬리 데이터(long-tail facts)나 역방향 질문에서 이러한 문제가 두드러졌으며, 추론을 통해 회수율을 크게 향상시킬 수 있었습니다. 이는 모델 스케일링보다는 기존 지식 활용 방법 개선에 더 집중해야 함을 시사합니다.",
      "key_points": [
        "Factuality 평가 시 지식 습득과 접근 실패를 분리하는 프레임워크 제안",
        "자동 구축된 WikiProfile 벤치마크 소개",
        "최신 LLM에서 지식 접근 실패가 Factuality 저하의 주요 원인임을 입증"
      ],
      "tags": [
        "LLM",
        "Factuality",
        "Evaluation",
        "RAG",
        "Benchmark",
        "Inference"
      ],
      "confidence": "상",
      "adoption_complexity": "중",
      "practical_relevance": "LLM 기반 서비스를 개발할 때, 모델의 Factuality를 개선하기 위해 지식 습득뿐만 아니라 이미 학습된 정보를 효율적으로 검색하고 추론하는 메커니즘을 강화하는 것이 중요합니다.",
      "recommended_actions": [
        "RAG 시스템 구축 시, 모델이 검색된 정보를 바탕으로 추론할 수 있도록 프롬프팅 전략을 개선해보기",
        "기존 Factuality 평가 지표 외에, WikiProfile을 활용하여 모델의 지식 접근 능력을 평가해보기",
        "long-tail 데이터에 대한 Factuality 개선을 위해 fine-tuning 시 데이터 증강 기법을 활용해보기"
      ],
      "risks_and_limits": [
        "WikiProfile 벤치마크가 특정 지식 도메인에 편향되어 있을 수 있음",
        "모델의 '생각하기' 능력은 여전히 제한적이며, 복잡한 추론은 어려울 수 있음"
      ],
      "repeated_in_window": false,
      "repeated_days_ago": null,
      "image_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.14080.png",
      "local_image_path": "images/Empty_Shelves_or_Lost_Keys_Recall_Is_the_Bottleneck_for_Parametric_Factuality_img.jpg",
      "local_figures": []
    }
  ]
}